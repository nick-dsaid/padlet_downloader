{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1da941-bd65-49eb-b9c2-8320b4a97a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import wget\n",
    "import requests\n",
    "import logging\n",
    "import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cd176a-72bd-45b4-aef6-dc9ace169391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package loaded in Notebook Mode\n",
      "Successfully imported ds_utils as Package\n"
     ]
    }
   ],
   "source": [
    "from dsx.ds_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19aa92ce-df95-425c-a97e-19cc5905ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b2fefe-6e3d-4f7a-b6b9-ebcd0a7f30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='padlet_extract.log',\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "\n",
    "root = logging.getLogger()\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60d2298-a1fc-4432-afd5-25f45fdb6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_email_group = '(([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-\\-\\.]+(\\.[A-Z|a-z]{2,})+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98819fe7-50a2-47be-8f0d-3045ab9116e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: read emails and filter only to the emails\n",
    "df_email_to_filter = pd.read_excel('data/participants_x.xlsx')\n",
    "df_email_to_filter.email = df_email_to_filter.email.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304b965-3eaf-4576-bb4e-dd3ab4ef20ce",
   "metadata": {},
   "source": [
    "# Process the Downloaded Excel Files of the Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7725e-bf1a-4f7b-9e97-ff134d6d99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"filepath\", help=\"folder_name for the week\")\n",
    "parser.add_argument(\"-d\", \"--download\", action=\"store_true\", help=\"download files and generate filesize report.\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "current_folder = args.filepath\n",
    "download_bool = args.download\n",
    "\n",
    "logging.info(f\"current_file set as {current_folder}\")\n",
    "if download_bool:\n",
    "    logging.info(\"Files will be downloaded to generate filesize report. \\\n",
    "                 This can take more than 5 minutes to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4290cf8-1448-4c3e-8692-6b8da72eaf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Argument\n",
    "# This line not needed when executed in block\n",
    "current_folder = 'Week_01'\n",
    "download_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97daab07-2f5a-4ddb-bd74-3f3a615e6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in mapping file\n",
    "df_mapp = pd.read_csv('data/DC Bootcamp - Service Accounts-623d1b9a0126670012303866.csv', skiprows=5)\n",
    "df_mapp.ds.stdcols()\n",
    "\n",
    "df_mapp.Official_Email = df_mapp.Official_Email.str.lower()\n",
    "df_mapp.Official_Email = df_mapp.Official_Email.str.strip()\n",
    "df_mapp['email'] = df_mapp.Official_Email.str.extract(pat_email_group)[0]\n",
    "df_mapp.rename(columns={'Padlet_Username':'Author'}, inplace=True)\n",
    "\n",
    "df_mapp.drop_duplicates(['email'], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10dedc54-4091-4482-90ad-fd71e4c582a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Padlet Files\n",
    "dirpath = os.path.join('padlet_excel_files', current_folder)\n",
    "\n",
    "dff = []\n",
    "for filename in os.listdir(dirpath):\n",
    "    excel_file = pd.ExcelFile(os.path.join(dirpath, filename))\n",
    "    df_header = excel_file.parse(nrows=4)\n",
    "    padlet_name = \"_\".join(df_header.columns[1].split())\n",
    "    df = excel_file.parse(skiprows=5)\n",
    "    df.ds.stdcols()\n",
    "    \n",
    "    part_string_pat = \"Part \"\n",
    "    # Check if the week is using multiple \"Parts\"\n",
    "    mask = (df.Subject.str.contains(part_string_pat)==True) & (df.Attachment.isnull()==True) & (df.Author.isnull()==True)\n",
    "    if len(df[mask]) > 0:\n",
    "        df['Part'] = None\n",
    "        df.loc[mask, 'Part'] = df.Subject\n",
    "        df.Part = df.Part.fillna(method='ffill')\n",
    "        df = df[mask==False].copy()\n",
    "        df = df.ds.cols_shift(['Part'], 0)\n",
    "        \n",
    "    df['padlet_name'] = padlet_name\n",
    "    df = df.ds.cols_shift(['padlet_name'], 0)\n",
    "    df['email'] = df.Subject.str.extract('(\\[.+\\])')\n",
    "    df['email'] = df['email'].str[1:-1]\n",
    "    dff.append(df)\n",
    "\n",
    "df = pd.concat(dff, axis=0, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8eeabe-c827-4ace-9433-14c40c5cc312",
   "metadata": {},
   "source": [
    "## Merge Mapping File and Username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183d61ff-26a8-4fb7-ad99-ae34fa61049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There can be multiple \"(\" , use regex group for extration\n",
    "pat = re.compile('((?<=\\()[\\d\\w]+)')\n",
    "# if bracket exits, then extract username between brackets\n",
    "mask = (df.Author.str.find('(') != -1)\n",
    "df.loc[mask, 'Author'] = df[mask].Author.map(lambda x: pat.findall(x)[-1])\n",
    "# merging\n",
    "df = df.drop('email', axis=1).merge(df_mapp[['Author', 'email']], 'left', 'Author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e662a39-e282-42c7-be2b-a3a288fb09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Username not Registered in FormSG\n",
    "# Export in the last stage\n",
    "list_nonreg_authors = df[(df.email.isnull()) & (df.Author != 'Anonymous')].Author.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ddc93-d3bd-466e-8b9a-2765e18df5b5",
   "metadata": {},
   "source": [
    "## Safe Guard Summitter Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1d6224-948b-44f6-a289-70d4afb1c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_email_group = '(([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-\\-\\.]+(\\.[A-Z|a-z]{2,})+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14894b33-8c72-46ec-9543-5a4eeb1f4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Anonymous, try extract email from subject with regex\n",
    "df.loc[df.email.isnull(), 'email'] = df[df.email.isnull()].Subject.str.extract(pat_email_group)[0]\n",
    "df.loc[df.email.isnull(), 'email'] = df[df.email.isnull()].Body.str.extract(pat_email_group)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc116872-7123-465f-9299-c05d6941ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.email = df.email.str.lower()\n",
    "df.email = df.email.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07684a6-baa8-4dc9-aa6c-bd73d2e07ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Tz from UTC to +8\n",
    "df.Updated_At = pd.to_datetime(df.Updated_At)\n",
    "df.Created_At = pd.to_datetime(df.Created_At)\n",
    "\n",
    "df.Updated_At = df.Updated_At.dt.tz_convert('Asia/Singapore')\n",
    "df.Created_At = df.Updated_At.dt.tz_convert('Asia/Singapore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d661b8c-c0e8-48d4-8706-b542ece033eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Downloading the Task Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03567c1f-4cc3-408d-a05a-c2df10cd18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter before Downloading\n",
    "dff = df[df.email.isin(df_email_to_filter.email)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237ce2c-5457-4855-b219-76a958dbbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff = dff.iloc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe90b5-eb47-4d2a-98ed-e8a9e1b692a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This whole black only run if the \"--download\" argument is presence, which means \"download_bool\" is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36f5923-bc51-4193-b260-96c083a179d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_for_download(str: current_folder):\n",
    "    export_path = os.path.join(os.getcwd(), 'downloads', current_folder)\n",
    "    if os.path.exists(export_path) and os.path.isdir(export_path):\n",
    "        logging.warning(f'Export path exists at {export_path}')\n",
    "    else:\n",
    "        os.mkdir(export_path)\n",
    "        logging.info(f'Export path created at {export_path}')\n",
    "    return export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "136fd5c4-3179-4024-a288-d18bec067f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_files_create_report(df_filtered) -> pd.core.frame.DataFrame:\n",
    "    df_check_report = []\n",
    "\n",
    "    for i, row in tqdm.tqdm(df_filtered.iterrows(), total=len(df_filtered)):\n",
    "        if pd.isna(row.Attachment)==False:\n",
    "            try:\n",
    "                # Forming the filename for file to be downloaded\n",
    "                filename_toset = os.path.basename(row.Attachment).split('.')\n",
    "                filename_toset.insert(-1, \"_\" + row.email)\n",
    "                filename_toset = ''.join(filename_toset[:-1]) + '.' + filename_toset[-1]\n",
    "\n",
    "                path_file_download = os.path.join(export_path, filename_toset)\n",
    "                wget.download(row.Attachment, path_file_download)\n",
    "                file_size_kb = np.round(os.path.getsize(path_file_download) / 1024, 2)\n",
    "\n",
    "                row['local_relative_path'] = path_file_download\n",
    "                row['file_size_kb'] = file_size_kb\n",
    "                df_check_report.append(row)\n",
    "            except:\n",
    "                logging.warning(f'File download failed for row.email')\n",
    "\n",
    "    return pd.DataFrame(df_check_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2de57-6916-40e0-ae82-f5ddca10796d",
   "metadata": {},
   "source": [
    "# checking report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "612ba888-6e56-4554-900b-e32ff4cf577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Part' in dff.columns:\n",
    "    dff = dff.sort_values(['email', 'Part', 'Updated_At'], axis=0, ascending=True)\n",
    "    dff = dff.drop_duplicates(['email', 'Part'], keep='last')\n",
    "\n",
    "    df_report_submission = df_email_to_filter.merge(dff[['email', 'Part', 'Updated_At']], 'left', 'email')\n",
    "    df_report_submission = df_report_submission.pivot_table(index='email', columns='Part', values='Updated_At', dropna=False)\n",
    "    df_report_submission = df_report_submission.reset_index(drop=False)\n",
    "else:\n",
    "\n",
    "    dff = dff.sort_values(['email', 'Updated_At'], axis=0, ascending=True)\n",
    "    dff = dff.drop_duplicates(['email'], keep='last')\n",
    "    df_report_submission = dff[['email', 'Updated_At']].copy()\n",
    "    df_report_submission = df_report_submission.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "# Adding in Emails that have not submitted any files\n",
    "missing = df_email_to_filter[~df_email_to_filter.email.isin(df_report_submission.email)]\n",
    "df_temp = [{'email':x} for x in missing.email.tolist()]\n",
    "df_report_submission = df_report_submission.append(df_temp)\n",
    "\n",
    "df_report_submission = df_report_submission.merge(df_email_to_filter, 'left', 'email')\n",
    "df_report_submission = df_report_submission.ds.cols_shift('agency', 'left')\n",
    "df_report_submission = df_report_submission.sort_values(['agency', 'email'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7010c5a-c46d-444f-8ce0-275da9b2e928",
   "metadata": {},
   "source": [
    "# Exporting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb54b3-f2cf-4c86-bece-399f8ab564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, dfg in df_report_submission.groupby('agency'):\n",
    "    dfg.to_csv(os.path.join('reports', current_folder + f'_{g}_submission_report.csv'), index=False)\n",
    "    \n",
    "logging.info(\"Submission_report(s) have been exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee390e4-642a-4e64-86c6-d0afe96af11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting to download files and generate fileszie report\")\n",
    "\n",
    "if download_bool:\n",
    "    export_path = create_folder_for_download(current_folder)\n",
    "    df_report = download_files_create_report(dff)\n",
    "    df_report = df_report.merge(df_email_to_filter, 'left', 'email')\n",
    "\n",
    "    for g, dfg in df_report.groupby('agency'):\n",
    "        dfg.to_csv(os.path.join('reports', current_folder + f'_{g}_filesize_report.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b1b4d-f039-4024-8274-9fd886dba2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Program executed completely. Terminated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e788de2-2ed9-4b4f-8f90-523f38fd5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_nonreg = pd.DataFrame(list_nonreg_authors).reset_index()\n",
    "# df_nonreg.columns = ['No', 'Padlet_Username']\n",
    "# df_nonreg.to_html('DCBootcamp_Padlet_Usernames.html', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416800e-f6e2-4219-bff6-281bb1a0ce69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
